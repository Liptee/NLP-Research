Исходя из всего проведенного исследования современных токенизаторов, для проведения тестов были выбраны следующие:
1. Rule-Based Tokenizers:
	1.1 `WordPunct` входящий в состав библиотеки NLTK.
	1.2 `Standford CoreNLP` 

2. Statistical Tokenizers:
	2.1 `Spacy` 
	2.2 `Moses`

3. Neutal Network-Based Tokenizers:
	3.1 `BERT`
	3.2 `RoBERTa`
	3.3 `Hugging Face`
	3.4 `GPT`
	3.5 `Electra`